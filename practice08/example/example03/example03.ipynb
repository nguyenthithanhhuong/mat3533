{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khai báo các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 77760 243 320\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/Code/python/mat3533/practice08/data/face_data/'\n",
    "ids = range(1, 16) # 15 people\n",
    "states = ['centerlight', 'glasses', 'happy', 'leftlight',\n",
    "'noglasses', 'normal', 'rightlight','sad',\n",
    "'sleepy', 'surprised', 'wink' ]\n",
    "prefix = 'subject'\n",
    "surfix = '.png' #file extension is png\n",
    "# open one picture to get the image's size\n",
    "fn = prefix + '01.' + states[0] + surfix\n",
    "im = cv2.imread(path + fn, 0)\n",
    "h = im.shape[0] # hight\n",
    "w = im.shape[1] # width\n",
    "D = h * w\n",
    "N = len(states)*15\n",
    "print(N, D, h, w)\n",
    "X = np.zeros((D, N))\n",
    "# collect all data\n",
    "count = 0\n",
    "# there are 15 people\n",
    "for person_id in range(1, 16):\n",
    "    for state in states:\n",
    "        # get name of each image file\n",
    "        fn = path + prefix + str(person_id).zfill(2) + '.' + state + surfix\n",
    "        # open the file and read as grey image\n",
    "        tmp = cv2.imread(fn, cv2.IMREAD_GRAYSCALE)\n",
    "        # then add image to dataset X\n",
    "        X[:, count] = tmp.reshape(D)\n",
    "        count += 1\n",
    "y = np.repeat(range(1, 16), len(states))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phân chia dữ  liệu theo tỉ lệ train:test=0.8:0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.T, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=16)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "\n",
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Reshape((243,320,1),input_shape=(77760,)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, \n",
    "                                 kernel_size=(3,3), \n",
    "                                 activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(16, activation='softmax'))\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.0487 - loss: 50.7819 - val_accuracy: 0.0606 - val_loss: 152.7256\n",
      "Epoch 2/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.1965 - loss: 12.2430 - val_accuracy: 0.2727 - val_loss: 5.1503\n",
      "Epoch 3/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6033 - loss: 1.4740 - val_accuracy: 0.7879 - val_loss: 0.3568\n",
      "Epoch 4/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9707 - loss: 0.4044 - val_accuracy: 0.5758 - val_loss: 1.5881\n",
      "Epoch 5/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0709 - val_accuracy: 0.7879 - val_loss: 0.5447\n",
      "Epoch 6/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 0.9091 - val_loss: 0.3487\n",
      "Epoch 7/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.8788 - val_loss: 0.3482\n",
      "Epoch 8/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8788 - val_loss: 0.2508\n",
      "Epoch 9/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.8788 - val_loss: 0.3458\n",
      "Epoch 10/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 7.8794e-04 - val_accuracy: 0.8788 - val_loss: 0.3614\n",
      "Epoch 11/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 6.0107e-04 - val_accuracy: 0.8788 - val_loss: 0.3609\n",
      "Epoch 12/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 8.3216e-04 - val_accuracy: 0.9091 - val_loss: 0.3703\n",
      "Epoch 13/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.0923e-04 - val_accuracy: 0.9091 - val_loss: 0.3660\n",
      "Epoch 14/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 9.7163e-05 - val_accuracy: 0.9091 - val_loss: 0.3578\n",
      "Epoch 15/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9091 - val_loss: 0.3509\n",
      "Epoch 16/16\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 2.4626e-04 - val_accuracy: 0.9091 - val_loss: 0.3482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x170f4905f90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,          \n",
    "          validation_data=(X_test,y_test),\n",
    "          epochs=16,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13, 11, 12,  6,  9,  3, 15,  5, 10, 14,  2,  8,  2, 10,  3,  3, 13,\n",
       "       10, 14,  2,  7,  2,  1,  1,  9, 15,  9,  6, 13, 15, 13,  8,  6],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.argmax(axis = 1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 405ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 385ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 381ms/step\n",
      "Accuracy on train set: 1.0\n",
      "Recall on train set: 1.0\n",
      "Precision on train set: 1.0\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = tf.keras.metrics.Accuracy()\n",
    "train_recall = tf.keras.metrics.Recall()\n",
    "train_precision = tf.keras.metrics.Precision()\n",
    "\n",
    "train_accuracy.update_state(tf.argmax(y_train, axis=1), tf.argmax(model.predict(X_train), axis=1))\n",
    "train_acc = train_accuracy.result().numpy()\n",
    "train_recall.update_state(y_train, model.predict(X_train))\n",
    "train_precision.update_state(y_train, model.predict(X_train))\n",
    "\n",
    "print(\"Accuracy on train set:\", train_acc)\n",
    "print(\"Recall on train set:\", train_recall.result().numpy())\n",
    "print(\"Precision on train set:\", train_precision.result().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step \n",
      "Recall on test set: 0.90909094\n",
      "Precision on test set: 0.90909094\n",
      "Accuracy on test set: 0.90909094\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "test_recall = tf.keras.metrics.Recall()\n",
    "test_precision = tf.keras.metrics.Precision()\n",
    "\n",
    "test_accuracy.update_state(tf.argmax(y_test, axis=1), tf.argmax(model.predict(X_test), axis=1))\n",
    "test_acc = test_accuracy.result().numpy()\n",
    "test_recall.update_state(y_test, model.predict(X_test))\n",
    "test_precision.update_state(y_test, model.predict(X_test))\n",
    "\n",
    "print(\"Recall on test set:\", test_recall.result().numpy())\n",
    "print(\"Precision on test set:\", test_precision.result().numpy())\n",
    "print(\"Accuracy on test set:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
