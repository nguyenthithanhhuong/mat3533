{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lấy dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 3 classes.\n",
      "Found 750 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "def train_test_animals():\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    # Số lượng ảnh mỗi lớp cho tập huấn luyện và tập kiểm tra\n",
    "    images_per_class_train = 750\n",
    "    images_per_class_test = 250\n",
    "\n",
    "    # Tạo ImageDataGenerator\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
    "\n",
    "    # Tạo tập huấn luyện\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        'D:/Code/python/mat3533/practice08/data/CNN_MultiClass_data/animals',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=images_per_class_train,  # Lấy hết ảnh trong mỗi lớp cho tập huấn luyện\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True  # Xáo trộn dữ liệu\n",
    "    )\n",
    "\n",
    "    # Tạo tập kiểm tra\n",
    "    test_generator = train_datagen.flow_from_directory(\n",
    "        'D:/Code/python/mat3533/practice08/data/CNN_MultiClass_data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=images_per_class_test,  # Lấy hết ảnh trong mỗi lớp cho tập kiểm tra\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=True  # Xáo trộn dữ liệu\n",
    "    )\n",
    "\n",
    "    # Lấy ảnh và nhãn từ tập dữ liệu\n",
    "    train_images, labels_train = next(train_generator)\n",
    "    test_images, labels_test = next(test_generator)\n",
    "\n",
    "    return train_images, test_images, labels_train, labels_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_animals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuẩn bị dữ liệu train, test để phân loại 2 lớp chó, mèo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(images, labels, class_indices, num_images):\n",
    "    filtered_images = []\n",
    "    filtered_labels = []\n",
    "    for i, label in enumerate(labels):\n",
    "        if label[class_indices[0]] == 1 or label[class_indices[1]] == 1:\n",
    "            filtered_images.append(images[i])\n",
    "            if label[class_indices[0]] == 1:\n",
    "                filtered_labels.append(0)  # Nhãn cho lớp 0\n",
    "            else:\n",
    "                filtered_labels.append(1)  # Nhãn cho lớp 1\n",
    "            num_images -= 1\n",
    "            if num_images == 0:\n",
    "                break\n",
    "    return np.array(filtered_images), np.array(filtered_labels)\n",
    "\n",
    "class_indices = [0, 1]\n",
    "\n",
    "X_train, y_train = get_data(X_train, y_train, class_indices, 150)\n",
    "\n",
    "X_test, y_test = get_data(X_test, y_test, class_indices, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khởi tạo mô hình CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # 2 lớp đầu ra với softmax activation\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huấn luyện và chạy dự đoán mô hình CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.5000 - val_loss: 2.5000\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.9869 - loss: 0.0286 - val_accuracy: 0.5100 - val_loss: 4.0727\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.5600 - val_loss: 2.8132\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.5000 - val_loss: 3.1321\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5100 - val_loss: 3.7666\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5100 - val_loss: 3.8586\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 8.8923e-04 - val_accuracy: 0.5000 - val_loss: 3.4932\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 6.1262e-04 - val_accuracy: 0.5100 - val_loss: 3.3707\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 5.1476e-04 - val_accuracy: 0.5100 - val_loss: 3.3991\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 5.0049e-04 - val_accuracy: 0.5100 - val_loss: 3.4859\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
