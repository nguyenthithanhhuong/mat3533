{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khai báo các thư vienj cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đọc dữ liệu và chia dữ liệu theo tỉ lệ: train:validation = 4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :4]\n",
    "Y = iris.target\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các phương thức cần thiết cho mô hình hồi quy Logistic nhiều lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 3\n",
    "def convert_labels(y, C = C):\n",
    "    \"\"\"\n",
    "    convert 1d label to a matrix label: each column of this\n",
    "    matrix coresponding to 1 element in y. In i-th column of Y,\n",
    "    only one non-zeros element located in the y[i]-th position,\n",
    "    and = 1 ex: y = [0, 2, 1, 0], and 3 classes then return\n",
    "\n",
    "            [[1, 0, 0, 1],\n",
    "             [0, 0, 1, 0],\n",
    "             [0, 1, 0, 0]]\n",
    "    \"\"\"\n",
    "    Y = sparse.coo_matrix((np.ones_like(y),\n",
    "        (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
    "    return Y\n",
    "\n",
    "\n",
    "def softmax_stable(Z):\n",
    "    \"\"\"\n",
    "    Compute softmax values for each sets of scores in Z.\n",
    "    each column of Z is a set of score.\n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z - np.max(Z, axis = 0, keepdims = True))\n",
    "    A = e_Z / e_Z.sum(axis = 0)\n",
    "    return A\n",
    "\n",
    "def softmax(Z):\n",
    "    \"\"\"\n",
    "    #Compute softmax values for each sets of scores in V.\n",
    "    #each column of V is a set of score.\n",
    "    \"\"\"\n",
    "    e_Z = np.exp(Z)\n",
    "    A = e_Z / e_Z.sum(axis = 0)\n",
    "    return A\n",
    "\n",
    "def softmax_regression(X, y, W_init, eta, tol = 1e-4, max_count = 10000):\n",
    "    W = [W_init]\n",
    "    C = W_init.shape[1]\n",
    "    Y = convert_labels(y, C)\n",
    "    it = 0\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "\n",
    "    count = 0\n",
    "    check_w_after = 20\n",
    "    while count < max_count:\n",
    "        # mix data\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = Y[:, i].reshape(C, 1)\n",
    "            ai = softmax(np.dot(W[-1].T, xi))\n",
    "            W_new = W[-1] + eta*xi.dot((yi - ai).T)\n",
    "            count += 1\n",
    "            # stopping criteria\n",
    "            if count%check_w_after == 0:\n",
    "                if np.linalg.norm(W_new - W[-check_w_after]) < tol:\n",
    "                    return W\n",
    "            W.append(W_new)\n",
    "    return W\n",
    "\n",
    "# cost or loss function\n",
    "def cost(X, Y, W):\n",
    "    A = softmax(W.T.dot(X))\n",
    "    return -np.sum(Y*np.log(A))\n",
    "\n",
    "# Predict that X belong to which class (1..C now indexed as 0..C-1 )\n",
    "def pred(W, X):\n",
    "    \"\"\"\n",
    "    predict output of each columns of X\n",
    "    Class of each x_i is determined by location of max probability\n",
    "    Note that class are indexed by [0, 1, 2, ...., C-1]\n",
    "    \"\"\"\n",
    "    A = softmax_stable(W.T.dot(X))\n",
    "    return np.argmax(A, axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ra bộ hệ số của mô hình "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.73871626  2.21402564 -5.0062918 ]\n",
      " [ 2.45825632  0.90897683 -3.15016637]\n",
      " [ 2.40372996  0.04267035 -5.23905817]\n",
      " [-5.76619147 -1.29183113  5.97062684]\n",
      " [-2.90128806 -2.88137854  5.18987667]]\n"
     ]
    }
   ],
   "source": [
    "one_train = np.ones((X_train.shape[0], 1))\n",
    "Xbar_train = np.concatenate((one_train, X_train), axis = 1).T\n",
    "\n",
    "eta = .05\n",
    "d = X.T.shape[0]\n",
    "W_init = np.random.randn(Xbar_train.shape[0], C)\n",
    "W = softmax_regression(Xbar_train, Y_train, W_init, eta)\n",
    "print(W[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dự đoán dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 2 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "one_test = np.ones((X_test.shape[0], 1))\n",
    "Xbar_test = np.concatenate((one_test, X_test), axis = 1).T\n",
    "y_predict = pred(W[-1], Xbar_test)\n",
    "print(y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
